<!DOCTYPE html>
<html lang='en'>

<head>
    <base href="..">
    <link rel="shortcut icon" type="image/png" href="assets/favicon-32x32.png"/>
    <link rel="stylesheet" type="text/css" media="all" href="assets/main.css"/>
    <script type="text/javascript" async
        src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/MathJax.js?config=default">
    </script>
    <meta name="description" content="Conference Template">
    <meta name="resource-type" content="document">
    <meta name="distribution" content="global">
    <meta name="KeyWords" content="Conference">
    <title>Program | Conference Template</title>
</head>

<body>

    <div class="banner">
        <img src="assets/atl-banner.jpeg" alt="Conference Template Banner", height="350", width="1000">
        <div class="top-left">
            <span style="font-size: 40px;">2nd Student-Focused <span style="color:rgb(202, 82, 22);">SciML Symposium @ GT 2024</span></span>
        </div>
        <div class="bottom-right">
            Virtual Symposium <br>19th & 21st Nov, 2024
        </div>
    </div>

    <table class="navigation">
        <tr>
            <td class="navigation">
                <a class="current" title="Conference Home Page" href=".">Home</a>
            </td>
            <td class="navigation">
                <a title="Register for the Conference" href="registration">Registration</a>
            </td>
            <td class="navigation">
                <a title="Conference Program" href="program">Program</a> 
            </td>
        </tr>
    </table>

    <h2>Conference Program</h2>

    <h3>19th Nov, 2023 - Session 1</h3>

    <table>
        <tr>
            <td class="date" rowspan="2">
                8:00-8:05 AM ET
            </td>
            <td class="title-special">
                Introductions - The Symposium begins
            </td>
        </tr>
        <tr>
            <td class="abstract">
                All participants and speakers are welcomed to the first Sci-ML symposium!
            </td>
        </tr>
    </table>

    <table class="plenary">
        <tr>
            <td class="date" rowspan="3">
                8:05-8:20 AM ET
            </td>
            <td class="title-special">
                Enhancing Option Pricing with Neural ODEs and SDEs
            </td>
        </tr>
        <tr>
            <td class="abstract">
                Team Sharpe Explorers
            </td>
        </tr>
    </table>
    <table class="plenary">
        <tr>
            <td class="date" rowspan="3">
                8:20-8:35 AM ET
            </td>
            <td class="title-special">
                Enhancing Epidemic Forecasting Through Hybrid ML and Epidemiological Models
            </td>
        </tr>
        <tr>
            <td class="abstract">
                Team Py-Iguana
            </td>
        </tr>
    </table>
    <table class="plenary">
        <tr>
            <td class="date" rowspan="3">
                8:35-8:50 AM ET
            </td>
            <td class="title-special">
                Scientific Machine Learning for Generalized Drug-Target Interaction Prediction
            </td>
        </tr>
        <tr>
            <td class="abstract">
                Team Polaris
            </td>
        </tr>
    </table>

    <table id="PUTSPEAKERNAMEHERE">
        <tr>
            <td class="date" rowspan="3">
                8:50-9:15 AM ET
            </td>
            <td class="title-special">
                Staying grounded: scientific machine learning with physical inductive biases
            </td>
        </tr>
        <tr>
            <td class="speaker">
                Jack Richter-Powell (Massachusetts Institute of Technology)
            </td>
        </tr>
        <tr>
            <td class="abstract">
                Applying machine learning methods to problems in the physical sciences has proven successful in a variety of different settings. Specifically, there have been a number of cases where ML methods have yielded more accurate results than conventional hand developed numerical methods - a far from exhaustive set of examples includes: protein folding (AlphaFold), weather forecasting 
                (FourCastNet among others) and simulation of quantum states in computational chemistry (Ferminet/DeepQMC). These advancements have demonstrated the efficacy of applying machine learning in these domains, but questions remains over the validity of these learned approaches when compared to their classical counterparts. Namely, many classical numerical solvers can be shown to enforce certain governing physical 
                principles by construction, and often it is also possible to identify their failure modes by analyzing the mathematical structure of their algorithms. By contrast, ML and more specifically deep learning methods, come without these guarantees, as well as proving harder if not impossible to analyze.  In this talk, we'll examine a few of 
                my past and ongoing works bridging this gap by incorporating principled inductive biases into machine learning models. We'll discuss how this combination allows us to enjoy the increased power and flexibility of modern machine learning without sacrificing all the benefits classical numerical methods provide.
            </td>
        </tr>
    </table>

    <h3>21st Nov, 2023 - Session 2</h3>

    <table id="PUTSPEAKERNAMEHERE">
        <tr>
            <td class="date" rowspan="3">
                8:10-8:35 AM ET
            </td>
            <td class="title-special">
                Federated scientific machine learning for approximating functions and solving differential equations
            </td>
        </tr>
        <tr>
            <td class="speaker">
                Handi Zhang (University of Pennsylvania)
            </td>
        </tr>
        <tr>
            <td class="abstract">
                Neural networks have revolutionized the domain of scientific machine learning (SciML), offering innovative approaches to tackle complex problems governed by partial differential equations (PDEs). In real-world applications, training datasets that these data-drive methods rely on may not store in the centralized format, and the concerns of data privacy may result in communi- cation inefficiency and leave the potential improvement of collaboratively trained deep learning models. 
                Federated Learning (FL), as a decentralized approach that collaboratively trains the global model with reserved data privacy, addresses the issues of isolated data pools and sensitive data concerns. This talk delves into the integration of federated learning with scientific machine learning to approximate complex functions and solve differential equations. First, we proposed various data assignment methods to distribute datasets across local clients to control non-iid levels in synthetic data under regression setting. 
                Subsequently, we quantified the level of data heterogeneity in approximating functions and learning PDE solutions by utilizing the 1-Wasserstein distance and systematically exploring the relationship between non-iidness and performance of federated models. Experiments encompass various PDEs, including both inverse and forward problems in 1D and 2D, and demonstrates that incorporation of federated learning with PINNs and DeepONet preserves satisfactory accuracy and promotes efficient parallel training.
            </td>
        </tr>
    </table>

    <table class="plenary">
        <tr>
            <td class="date" rowspan="3">
                8:35-8:45 AM ET
            </td>
            <td class="title-special">
                Increasing Efficiency of DFT with Surrogate Models of Graph Embeddings
            </td>
        </tr>
        <tr>
            <td class="abstract">
                Team Efficient DFT
            </td>
        </tr>
    </table>
    <table class="plenary">
        <tr>
            <td class="date" rowspan="3">
                8:50-9:05 AM ET	
            </td>
            <td class="title-special">
                Innovating Autonomous Robotics with Dual-Task Machine Learning for Navigation and Stability
            </td>
        </tr>
        <tr>
            <td class="abstract">
                Team Stardust
            </td>
        </tr>
    </table>
    <table class="plenary">
        <tr>
            <td class="date" rowspan="3">
                9:05-9:15 AM ET	
            </td>
            <td class="title-special">
                Solar Flare Peak Emission Flux Prediction
            </td>
        </tr>
        <tr>
            <td class="abstract">
                Team AutoCV
            </td>
        </tr>
    </table>

    <footer>
        &copy; Conference Organizers Sci-ML@GaTech
        &nbsp;|&nbsp; Design by <a href="https://github.com/mikepierce">Mike Pierce</a> and <a href="https://10-zin.github.io/">Tenzin Bhotia</a>
    </footer>

</body>
</html>

